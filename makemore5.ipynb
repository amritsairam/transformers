{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "words = open('/Users/sairam/Downloads/makemore-master/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle up the words\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, 25],\n",
       "        [ 0,  0,  0,  0,  0,  0, 25, 21],\n",
       "        [ 0,  0,  0,  0,  0, 25, 21,  8],\n",
       "        [ 0,  0,  0,  0, 25, 21,  8,  5],\n",
       "        [ 0,  0,  0, 25, 21,  8,  5, 14],\n",
       "        [ 0,  0, 25, 21,  8,  5, 14,  7],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  4],\n",
       "        [ 0,  0,  0,  0,  0,  0,  4,  9],\n",
       "        [ 0,  0,  0,  0,  0,  4,  9, 15],\n",
       "        [ 0,  0,  0,  0,  4,  9, 15, 14],\n",
       "        [ 0,  0,  0,  4,  9, 15, 14,  4],\n",
       "        [ 0,  0,  4,  9, 15, 14,  4, 18],\n",
       "        [ 0,  4,  9, 15, 14,  4, 18,  5],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0, 24,  1],\n",
       "        [ 0,  0,  0,  0,  0, 24,  1, 22],\n",
       "        [ 0,  0,  0,  0, 24,  1, 22,  9],\n",
       "        [ 0,  0,  0, 24,  1, 22,  9,  5],\n",
       "        [ 0,  0, 24,  1, 22,  9,  5, 14],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, 10],\n",
       "        [ 0,  0,  0,  0,  0,  0, 10, 15]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n",
      "..yuheng --> .\n",
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n",
      "........ --> x\n",
      ".......x --> a\n",
      "......xa --> v\n",
      ".....xav --> i\n",
      "....xavi --> e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 68)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size,n_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22397\n"
     ]
    }
   ],
   "source": [
    "#original network\n",
    "#vocab_size=27\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 68 # the number of neurons in the hidden layer of the MLP\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "# hierarchical network\n",
    "# n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "# n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
    "# model = Sequential([\n",
    "#   Embedding(vocab_size, n_embd),\n",
    "#   FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "#   FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "#   FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "#   Linear(n_hidden, vocab_size),\n",
    "# ])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3142\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits=model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update: simple SGD\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m layers\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8fc8ed1dc0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[200, -1]' is invalid for input of size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mplot(torch\u001b[39m.\u001b[39;49mtensor(lossi)\u001b[39m.\u001b[39;49mview(\u001b[39m200\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mmean(\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[200, -1]' is invalid for input of size 1"
     ]
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(200,-1).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182625, 27])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=model(Xtr)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.9193568229675293\n",
      "val 2.024869203567505\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits=model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split,loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remuold.\n",
      "caryuea.\n",
      "casanna.\n",
      "hemudn.\n",
      "lourien.\n",
      "aayaus.\n",
      "khaloise.\n",
      "xkvum.\n",
      "remsin.\n",
      "iyane.\n",
      "akhloy.\n",
      "anresla.\n",
      "kifzy.\n",
      "kamie.\n",
      "adetza.\n",
      "daaliby.\n",
      "mazie.\n",
      "nikolle.\n",
      "kamila.\n",
      "jazevia.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 8]), torch.Size([32]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape,Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  9, 22],\n",
       "        [ 0,  0, 13,  1,  4,  4,  9, 12],\n",
       "        [ 0,  0,  1, 25, 15, 13,  9,  4],\n",
       "        [ 0,  0,  0,  0,  0,  0, 14,  1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix=torch.randint(0,Xtr.shape[0],(4,))\n",
    "Xb,Yb=Xtr[ix],Ytr[ix]\n",
    "logits=model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randn(4,80)@torch.randn(80,200)+torch.randn(200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above what we are doing is we are taking a batch size of 8 characters , and predicting 9th character, but the problem is each character is having a \n",
    "#embedding of 10 so intotal 80 inputs are going in to gether , which is resulting in sudden decreseae in size leading to accuracy of 2.\n",
    "#what we can do is we can take batchsize of 20 inputs (2 characters ) and pass it in batch of 4 paralelly , resulting in total 80 inputs but split in group of 2\n",
    "# so the input dimension feeding in will be (4,4,20) and our hidden layer expects 20 input now , we can simply do that by changing the view of flatten layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currently our input vector is (4,8,10) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
